import { useEffect, useRef, useState } from "react";

interface VolumeStats {
  current: number;  // í˜„ì¬ ë³¼ë¥¨
  max: number;      // ìµœëŒ€ ë³¼ë¥¨
  average: number;  // í‰ê·  ë³¼ë¥¨
}

// âœ… ë³¼ë¥¨ ì¸¡ì • (ê°œì„  ë²„ì „)
export const useVolume = (active: boolean) => {
  const [volume, setVolume] = useState(0);
  const [maxVolume, setMaxVolume] = useState(0);
  
  const rafRef = useRef<number | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const volumeSamplesRef = useRef<number[]>([]);  // âœ… ë³¼ë¥¨ ìƒ˜í”Œ ìˆ˜ì§‘

  // âœ… ì •ë¦¬ í•¨ìˆ˜
  const cleanup = () => {
    if (rafRef.current) {
      cancelAnimationFrame(rafRef.current);
      rafRef.current = null;
    }
    
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());  // âœ… ì˜¤íƒ€ ìˆ˜ì •
      streamRef.current = null;
    }
    
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }
  };

  useEffect(() => {
    if (!active) {
      cleanup();
      // âœ… ë¹„í™œì„±í™” ì‹œ ë³¼ë¥¨ ìƒ˜í”Œ ì´ˆê¸°í™”
      volumeSamplesRef.current = [];
      setVolume(0);
      return;
    }

    let analyser: AnalyserNode;
    let dataArray: Uint8Array;
    let isActive = true;  // âœ… cleanup ì‹œê·¸ë„

    const initAudio = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ 
          audio: {
            echoCancellation: true,  // âœ… ì—ì½” ì œê±°
            noiseSuppression: true,   // âœ… ë…¸ì´ì¦ˆ ì œê±°
            autoGainControl: false    // âœ… ìë™ ê²Œì¸ ì œì–´ ë¹„í™œì„±í™” (ë³¼ë¥¨ ì •í™•ë„)
          } 
        });

        if (!isActive) {
          stream.getTracks().forEach(track => track.stop());
          return;
        }

        streamRef.current = stream;
        const audioContext = new AudioContext();
        audioContextRef.current = audioContext;

        const source = audioContext.createMediaStreamSource(stream);
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 2048;
        analyser.smoothingTimeConstant = 0.3;  // âœ… ìŠ¤ë¬´ë”© ì¶”ê°€

        dataArray = new Uint8Array(analyser.frequencyBinCount);
        source.connect(analyser);

        const checkVolume = () => {
          if (!isActive) return;

          analyser.getByteTimeDomainData(dataArray);

          let sum = 0;
          for (let i = 0; i < dataArray.length; i++) {
            sum += Math.abs(dataArray[i] - 128);
          }

          // âœ… í‰ê·  ì§„í­ ê³„ì‚° (0 ~ 128 ë²”ìœ„)
          const avgAmplitude = sum / dataArray.length;
          
          // âœ… damage.tsì™€ ë§ì¶”ê¸° ìœ„í•´ 0~5 ë²”ìœ„ë¡œ ì •ê·œí™”
          // avgAmplitude: 0~128
          // ì¡°ìš©í•  ë•Œ: ~5, ë³´í†µ ë§ì†Œë¦¬: 10~30, í° ì†Œë¦¬: 40+
          // 5ë‹¨ê³„ë¡œ ë§¤í•‘: 0(ë¬´ìŒ), 1(ë§¤ìš°ì‘ìŒ), 2(ì‘ìŒ), 3(ë³´í†µ), 4(í¼), 5(ë§¤ìš°í¼)
          let normalizedVolume = 0;
          
          if (avgAmplitude < 5) {
            normalizedVolume = 0;
          } else if (avgAmplitude < 15) {
            normalizedVolume = 1;
          } else if (avgAmplitude < 25) {
            normalizedVolume = 2;
          } else if (avgAmplitude < 35) {
            normalizedVolume = 3;
          } else if (avgAmplitude < 50) {
            normalizedVolume = 4;
          } else {
            normalizedVolume = 5;
          }
          
          setVolume(normalizedVolume);
          
          // âœ… ìµœëŒ€ ë³¼ë¥¨ ì¶”ì 
          setMaxVolume(prev => Math.max(prev, normalizedVolume));
          
          // âœ… ë³¼ë¥¨ ìƒ˜í”Œ ìˆ˜ì§‘ (í‰ê·  ê³„ì‚°ìš©)
          volumeSamplesRef.current.push(normalizedVolume);
          
          // âœ… ìƒ˜í”Œì´ ë„ˆë¬´ ë§ì•„ì§€ì§€ ì•Šë„ë¡ ì œí•œ (ìµœê·¼ 100ê°œ)
          if (volumeSamplesRef.current.length > 100) {
            volumeSamplesRef.current.shift();
          }

          console.log("ğŸ”Š ë³¼ë¥¨:", {
            raw: avgAmplitude.toFixed(2),
            normalized: normalizedVolume,
            max: maxVolume
          });

          rafRef.current = requestAnimationFrame(checkVolume);
        };

        checkVolume();
      } catch (err) {
        console.error("âŒ ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨:", err);
        alert("ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.");
      }
    };

    initAudio();

    return () => {
      isActive = false;
      cleanup();
    };
  }, [active]);

  // âœ… í‰ê·  ë³¼ë¥¨ ê³„ì‚°
  const getAverageVolume = () => {
    if (volumeSamplesRef.current.length === 0) return 0;
    const sum = volumeSamplesRef.current.reduce((a, b) => a + b, 0);
    return Math.round(sum / volumeSamplesRef.current.length);
  };

  return {
    current: volume,      // í˜„ì¬ ì‹¤ì‹œê°„ ë³¼ë¥¨
    max: maxVolume,       // ìµœëŒ€ ë³¼ë¥¨
    average: getAverageVolume()  // í‰ê·  ë³¼ë¥¨
  };
};